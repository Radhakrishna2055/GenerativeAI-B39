{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLa09t1lZ0HvpT2bHTKwl0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radhakrishna2055/GenerativeAI-B39/blob/main/GenAI_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Error Metrics Calculation\n",
        "\n"
      ],
      "metadata": {
        "id": "DF8z5trLBOip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9WMgVPeBEz6",
        "outputId": "a7de9f32-7d94-40c6-ea87-4c70e78999c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error (MSE): 0.24600000000000147\n",
            "Root Mean Square Error (RMSE): 0.49598387070549127\n",
            "Mean Absolute Percentage Error (MAPE): 1.27%\n",
            "Mean Bias Error (MBE): -0.4600000000000016\n",
            "Correlation (R) value: 0.9999393575598503\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Data from Table 1\n",
        "y_actual = np.array([20, 30, 40, 50, 60])\n",
        "y_pred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])\n",
        "\n",
        "# Error Metrics calculations\n",
        "def mean_squared_error(y_actual, y_pred):\n",
        "    return np.mean((y_actual - y_pred) ** 2)\n",
        "\n",
        "def root_mean_squared_error(y_actual, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "\n",
        "def mean_absolute_percentage_error(y_actual, y_pred):\n",
        "    return np.mean(np.abs((y_actual - y_pred) / y_actual)) * 100\n",
        "\n",
        "def mean_bias_error(y_actual, y_pred):\n",
        "    return np.mean(y_actual - y_pred)\n",
        "\n",
        "def correlation_coefficient(y_actual, y_pred):\n",
        "    return np.corrcoef(y_actual, y_pred)[0, 1]\n",
        "\n",
        "# Calculate the error metrics\n",
        "mse = mean_squared_error(y_actual, y_pred)\n",
        "rmse = root_mean_squared_error(y_actual, y_pred)\n",
        "mape = mean_absolute_percentage_error(y_actual, y_pred)\n",
        "mbe = mean_bias_error(y_actual, y_pred)\n",
        "r_value = correlation_coefficient(y_actual, y_pred)\n",
        "\n",
        "print(f\"Mean Square Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Square Error (RMSE): {rmse}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
        "print(f\"Mean Bias Error (MBE): {mbe}\")\n",
        "print(f\"Correlation (R) value: {r_value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Evaluation Metrics Calculation"
      ],
      "metadata": {
        "id": "7O2oAdgHE5Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Data from Table 2 (flattened for calculation)\n",
        "y_actual_table2 = np.array([0, 0, 1, 1, 2, 0, 1, 1, 2, 2])\n",
        "y_pred_table2 = np.array([0, 0, 1, 0, 2, 0, 2, 1, 0, 2])\n",
        "\n",
        "# Evaluation Metrics calculations\n",
        "def precision(y_actual, y_pred):\n",
        "    return precision_score(y_actual, y_pred, average='macro')\n",
        "\n",
        "def recall(y_actual, y_pred):\n",
        "    return recall_score(y_actual, y_pred, average='macro')\n",
        "\n",
        "def f1(y_actual, y_pred):\n",
        "    return f1_score(y_actual, y_pred, average='macro')\n",
        "\n",
        "# Calculate the evaluation metrics\n",
        "precision_val = precision(y_actual_table2, y_pred_table2)\n",
        "recall_val = recall(y_actual_table2, y_pred_table2)\n",
        "f1_val = f1(y_actual_table2, y_pred_table2)\n",
        "\n",
        "print(f\"Precision: {precision_val}\")\n",
        "print(f\"Recall: {recall_val}\")\n",
        "print(f\"F1-score: {f1_val}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAn4edTkE0ay",
        "outputId": "ac907eed-157e-48ac-d98f-24b175514997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.7555555555555555\n",
            "Recall: 0.7222222222222222\n",
            "F1-score: 0.6944444444444443\n"
          ]
        }
      ]
    }
  ]
}